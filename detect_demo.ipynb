{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32894,
     "status": "ok",
     "timestamp": 1648303177595,
     "user": {
      "displayName": "èŒ…æ™¨è¾‰",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11126424014326517849"
     },
     "user_tz": 240
    },
    "id": "jcjAsoeeQnJD",
    "outputId": "871656de-06df-492a-bc80-3211984d8979"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maochenhui/miniforge3/envs/DL/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp2/weights/best.pt'], source=dataset/Fall_Detection_Object/Test/, data=data/custom.yaml, imgsz=[416, 416], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ 629504c torch 1.10.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 1760518 parameters, 0 gradients, 4.2 GFLOPs\n",
      "image 1/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000000.png: 320x416 1 person, Done. (0.027s)\n",
      "image 2/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000001.png: 320x416 1 person, Done. (0.026s)\n",
      "image 3/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000002.png: 320x416 1 person, Done. (0.026s)\n",
      "image 4/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000003.png: 320x416 1 person, Done. (0.025s)\n",
      "image 5/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000004.png: 320x416 1 person, Done. (0.025s)\n",
      "image 6/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000005.png: 320x416 1 person, Done. (0.025s)\n",
      "image 7/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000006.png: 320x416 2 persons, Done. (0.025s)\n",
      "image 8/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000007.png: 320x416 1 person, Done. (0.026s)\n",
      "image 9/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000008.png: 320x416 1 person, Done. (0.026s)\n",
      "image 10/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000009.png: 320x416 1 person, Done. (0.026s)\n",
      "image 11/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000010.png: 320x416 1 person, Done. (0.026s)\n",
      "image 12/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000011.png: 320x416 1 person, Done. (0.028s)\n",
      "image 13/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000012.png: 320x416 1 person, Done. (0.027s)\n",
      "image 14/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000013.png: 320x416 1 person, Done. (0.026s)\n",
      "image 15/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000014.png: 320x416 1 person, Done. (0.026s)\n",
      "image 16/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000015.png: 320x416 1 person, Done. (0.026s)\n",
      "image 17/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000016.png: 320x416 1 person, Done. (0.026s)\n",
      "image 18/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000017.png: 320x416 1 person, Done. (0.027s)\n",
      "image 19/19 /Users/maochenhui/Python/pycharm_workspace/E6692/Fall_Detection/dataset/Fall_Detection_Object/Test/Fall_Person_valid_000018.png: 320x416 1 person, Done. (0.027s)\n",
      "Speed: 0.2ms pre-process, 26.1ms inference, 0.2ms NMS per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./detect/yolo/detect.py --weights runs/train/exp2/weights/best.pt --source dataset/Fall_Detection_Object/Test/ --img 416 --data  data/custom.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KnKK-18TSI9T"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP8oCxhBF57a/eqElq2mWwm",
   "collapsed_sections": [],
   "name": "detect_demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
